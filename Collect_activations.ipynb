{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General support\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# General lucid code\n",
    "import lucid.modelzoo.vision_models as models\n",
    "from lucid.modelzoo.vision_models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'model': 'Dd_m2_3_gpu_tf_pdtest',\n",
    "    'split': 'train'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.load(\"/Users/longm/Desktop/Dd_m2_3_gpu_tf_pbtest.pb\")\n",
    "model.load_graphdef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/longm/Desktop/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size = (256,256), batch_size = 25, class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train) = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = tf.reshape(x_train, [25,256,256,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_batch = tf.reshape(y_train, [25,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lucid.optvis import render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = render.import_model(model, image_batch, image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(base_dir, options, activations, attributions):\n",
    "\n",
    "  # spatial activations\n",
    "  activations_path = optionsToURL(base_dir + \"activations\", \"npy\", options)\n",
    "  with gfile.GFile(activations_path, \"w\") as f:\n",
    "    np.save(f, activations)\n",
    "\n",
    "  # spatial attributions to final classes\n",
    "  attributions_path = optionsToURL(base_dir + \"attribution\", \"npy\", options)\n",
    "  with gfile.GFile(attributions_path, \"w\") as f:\n",
    "    np.save(f, attributions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_gradients(ys, xs, d_xs):\n",
    "  \n",
    "  v = tf.zeros_like(ys)\n",
    "  g = tf.gradients(ys, xs, grad_ys=v)\n",
    "  return tf.gradients(g, v, grad_ys=d_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_images = int(25)\n",
    "options['sample_images'] = number_of_images\n",
    "number_of_pages = 1\n",
    "number_of_images_per_page = number_of_images / number_of_pages\n",
    "\n",
    "layers = [\n",
    "  \"Conv2D\",\n",
    "  \"Conv2D_1\", \"Conv2D_2\", \"Conv2D_3\",\"Conv2D_4\", \n",
    "  \"Conv2D_5\", \"Conv2D_6\", \"Conv2D_7\", \"Conv2D_8\", \"Conv2D_9\", \"Conv2D_10\", \"Conv2D_11\", \"Conv2D_12\"\n",
    "]\n",
    "\n",
    "for layer_name in reversed(layers):\n",
    "  print()\n",
    "  print(layer_name)\n",
    "  options['layer'] = layer_name\n",
    "\n",
    "  d_previous = tf.placeholder(\"float32\")\n",
    "  d_logit = fwd_gradients(T(\"output\"), T(layer_name), d_previous)[0]\n",
    "\n",
    "  \n",
    "  zeros = None\n",
    "  print(number_of_pages)\n",
    "  \n",
    "  for p in range(int(1)):\n",
    "    activations = []\n",
    "    attributions = []\n",
    "  \n",
    "    for n in range(int(25)):\n",
    "\n",
    "      # evaluate\n",
    "#      vec, image, label = sess.run([T(layer_name), x_train, y_train])\n",
    "      vec = sess.run([T(layer_name)])\n",
    "      image_other = sess.run([image_batch])\n",
    "      label = sess.run([labels_batch])\n",
    "\n",
    "      # sample one random position in the image, minus the edges\n",
    "      options['sample_type'] = 'random'\n",
    "      n_x = np.random.randint(1, vec.shape[1])\n",
    "      n_y = np.random.randint(1, vec.shape[2])\n",
    "      \n",
    "      # Compute logit attribution\n",
    "      if zeros is None:\n",
    "        zeros = np.zeros(vec.shape)\n",
    "      else:\n",
    "        zeros[:] = 0\n",
    "      zeros[0, n_x, n_y] = vec[0, n_x, n_y]\n",
    "      logit_attr = d_logit.eval({T(layer_name): vec, d_previous: zeros})\n",
    "\n",
    "      # top attributions for spatial activation:\n",
    "      top_attribution_class_index = int(np.argsort(-logit_attr[0])[0])\n",
    "      top_attribution_class_label = model.labels[top_attribution_class_index]\n",
    "\n",
    "      activations.append(vec[0, n_x, n_y])\n",
    "      attributions.append(logit_attr[0])\n",
    "\n",
    "    # progress indicator\n",
    "    print(p + 1)\n",
    "\n",
    "    # save files to bigstore\n",
    "    options['page'] = '{}_of_{}'.format(p + 1, number_of_pages)\n",
    "#    save_data(base_dir_gcs + layer_name + \"/\", options, activations, attributions)\n",
    "    save_data('/Users/longm/Desktop/collect_activations_model1/' + layer_name + '/', options, activations, attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
